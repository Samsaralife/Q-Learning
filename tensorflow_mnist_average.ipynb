{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/wangyingbo/Downloads/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/wangyingbo/Downloads/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/wangyingbo/Downloads/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/wangyingbo/Downloads/mnist/t10k-labels-idx1-ubyte.gz\n",
      "After 0 training step(s),validation accuracy,using average model is0.1172\n",
      "After 100 training step(s),validation accuracy,using average model is0.9314\n",
      "After 200 training step(s),validation accuracy,using average model is0.9444\n",
      "After 300 training step(s),validation accuracy,using average model is0.9574\n",
      "After 400 training step(s),validation accuracy,using average model is0.9592\n",
      "After 500 training step(s),validation accuracy,using average model is0.969\n",
      "After 600 training step(s),validation accuracy,using average model is0.9666\n",
      "After 700 training step(s),validation accuracy,using average model is0.967\n",
      "After 800 training step(s),validation accuracy,using average model is0.9676\n",
      "After 900 training step(s),validation accuracy,using average model is0.9716\n",
      "After 1000 training step(s),validation accuracy,using average model is0.9664\n",
      "After 1100 training step(s),validation accuracy,using average model is0.975\n",
      "After 1200 training step(s),validation accuracy,using average model is0.9736\n",
      "After 1300 training step(s),validation accuracy,using average model is0.9736\n",
      "After 1400 training step(s),validation accuracy,using average model is0.9742\n",
      "After 1500 training step(s),validation accuracy,using average model is0.9766\n",
      "After 1600 training step(s),validation accuracy,using average model is0.9778\n",
      "After 1700 training step(s),validation accuracy,using average model is0.9782\n",
      "After 1800 training step(s),validation accuracy,using average model is0.9792\n",
      "After 1900 training step(s),validation accuracy,using average model is0.9764\n",
      "After 2000 training step(s),validation accuracy,using average model is0.9782\n",
      "After 2100 training step(s),validation accuracy,using average model is0.98\n",
      "After 2200 training step(s),validation accuracy,using average model is0.9774\n",
      "After 2300 training step(s),validation accuracy,using average model is0.979\n",
      "After 2400 training step(s),validation accuracy,using average model is0.9814\n",
      "After 2500 training step(s),validation accuracy,using average model is0.9802\n",
      "After 2600 training step(s),validation accuracy,using average model is0.9788\n",
      "After 2700 training step(s),validation accuracy,using average model is0.9772\n",
      "After 2800 training step(s),validation accuracy,using average model is0.9826\n",
      "After 2900 training step(s),validation accuracy,using average model is0.9804\n",
      "After 3000 training steps(s),test accuracy using average, model is 0.9791\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyingbo/anaconda3/envs/tensorflow/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#MNIST数据集相关的数据\n",
    "INPUT_NODE = 784 #输入层的节点数。对于MNIST数据集，这个就是等于图片的像素\n",
    "OUTPUT_NODE = 10 #输出层的节点属于。这个等于类别的数目，因为在MNIST数据集中需要区分的是0~9这十个数字，所以这里输出层的节点数为10\n",
    "\n",
    "#配置神经网络的参数\n",
    "LAYER1_NODE = 500 #隐藏层节点数，这里使用只有一个隐藏层的网络结构作为样例，这个隐藏层有500个节点\n",
    "BATCH_SIZE = 100 #一个训练batch中的训练数据的个数，数据越小时，训练过程越接近随机梯度下降，数字越大，训练越接近梯度下降\n",
    "\n",
    "LEARNING_RATE_BASE = 0.8 #基础的学习率\n",
    "LEARNING_RATE_DECAY = 0.99 #学习率的衰减率\n",
    "REGULARIZATION_RATE = 0.0001 #描述模型复杂度的正则化项在损失函数中的系数\n",
    "\n",
    "TRANING_STEPS = 3000 #训练轮数\n",
    "MOVING_AVERAGE_DECAY = 0.99 #滑动平均衰减率\n",
    "\n",
    "#辅助函数，计算神经网络的钱箱传播结果\n",
    "def inference(input_tensor,avg_class,weight1,biase1,weight2,biase2):\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor,weight1) + biase1)\n",
    "        return tf.matmul(layer1,weight2) + biase2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor,avg_class.average(weight1)) + avg_class.average(biase1))\n",
    "        return tf.matmul(layer1,avg_class.average(weight2)) + avg_class.average(biase2)\n",
    "\n",
    "#训练模型的过程\n",
    "\n",
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32,[None,INPUT_NODE],name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32,[None,OUTPUT_NODE],name='y-output')\n",
    "    \n",
    "    #生成隐藏层的参数\n",
    "    weight1 = tf.Variable(tf.truncated_normal([INPUT_NODE,LAYER1_NODE],stddev=0.1))\n",
    "    biase1 = tf.Variable(tf.constant(0.1,shape=[LAYER1_NODE]))\n",
    "    \n",
    "    #生成输出层的参数\n",
    "    weight2 = tf.Variable(tf.truncated_normal([LAYER1_NODE,OUTPUT_NODE],stddev=0.1))\n",
    "    biase2 = tf.Variable(tf.constant(0.1,shape=[OUTPUT_NODE]))\n",
    "    \n",
    "    #所以函数不会使用参数的滑动平均值\n",
    "    y = inference(x,None,weight1,biase1,weight2,biase2)\n",
    "    \n",
    "    #定义存储训练轮数的变量,这个变量不需要计算滑动平均值，所以这里指定为不可训练的变量\n",
    "    global_step = tf.Variable(0,trainable=False)\n",
    "    \n",
    "    #给定滑动平均衰减率和训练轮数的变量，初始化滑动平均类\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)\n",
    "    #在所有代表神经网络参数的变量上使用滑动平均\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    #计算使用滑动平均之后的前向传播结果\n",
    "    average_y = inference(x,variable_averages,weight1,biase1,weight2,biase2)\n",
    "    \n",
    "    #损失函数\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_,1))\n",
    "    #计算在当前所有batch中所有样例的交叉熵平均值\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    #计算L2正则化损失函数\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    #计算模型的正则化损失\n",
    "    regularization = regularizer(weight1) + regularizer(weight2)\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    #设置指数衰减的学习率\n",
    "    learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE,global_step,mnist.train.num_examples/BATCH_SIZE,LEARNING_RATE_DECAY)\n",
    "    \n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step = global_step)\n",
    "    \n",
    "    #反向传播更新神经网络的参数\n",
    "    with tf.control_dependencies([train_step,variables_averages_op]):train_op = tf.no_op(name='train')\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #初始化变量\n",
    "        tf.global_variables_initializer().run()\n",
    "        #验证数据集\n",
    "        validate_feed = {x:mnist.validation.images,y_:mnist.validation.labels}\n",
    "        #测试数据集\n",
    "        test_feed = {x:mnist.test.images,y_:mnist.test.labels}\n",
    "        \n",
    "        for epoch in range(TRANING_STEPS):\n",
    "            xs,ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_step,feed_dict={x:xs,y_:ys})\n",
    "            if epoch % 100 == 0:\n",
    "                validate_acc = sess.run(accuracy,feed_dict=validate_feed)\n",
    "                print('After %d training step(s),validation accuracy,using average model is%g' %(epoch,validate_acc))\n",
    "            test_acc = sess.run(accuracy,feed_dict=test_feed)\n",
    "        print('After %d training steps(s),test accuracy using average, model is %g'%(TRANING_STEPS,test_acc))\n",
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets('/Users/wangyingbo/Downloads/mnist',one_hot=True)\n",
    "    train(mnist)\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
